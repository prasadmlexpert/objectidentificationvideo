{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoloV5CustomTrainingBDD100k.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadmlexpert/objectidentificationvideo/blob/main/YoloV7CustomTrainingBDD100k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training BDD data set using Yolov7"
      ],
      "metadata": {
        "id": "Aa5LpdIOOMjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 Setup YoloV7"
      ],
      "metadata": {
        "id": "u_xmg3PCPc9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click run `to download yolov7`.\n",
        "%%capture\n",
        "\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ],
      "metadata": {
        "id": "KDWqkAq1l3qR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click `To install requirement`.\n",
        "%%capture\n",
        "\n",
        "!pip install -r yolov7/requirements.txt"
      ],
      "metadata": {
        "id": "kjHD_SACskpR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click 'To install dependencies' \n",
        "%%capture\n",
        "!apt update\n",
        "!apt install -y zip htop screen libgl1-mesa-glx\n",
        "!pip install seaborn thop"
      ],
      "metadata": {
        "id": "c3CU7RDRMnDP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 2 Download BDD Data set"
      ],
      "metadata": {
        "id": "Jh-mc9l_Pf1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click `To download images`. { display-mode: \"form\" }\n",
        "!gdown 19eofB_tGB0xX-Qrt0zmvXiYj2bMPP9B1"
      ],
      "metadata": {
        "id": "AOGzpd912pR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346b27f3-692b-4e6d-c046-c9116447d1f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19eofB_tGB0xX-Qrt0zmvXiYj2bMPP9B1\n",
            "To: /content/bdd100k_images_100k.zip\n",
            "100% 5.81G/5.81G [01:01<00:00, 94.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.A Arrange BDD data set in folders"
      ],
      "metadata": {
        "id": "OCJraBJoOeyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip bdd100k_images_100k.zip"
      ],
      "metadata": {
        "id": "kJAISvramXTq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf bdd100k_images_100k.zip "
      ],
      "metadata": {
        "id": "CdYyeYdeWX3I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv bdd100k_images_100k/images /content/"
      ],
      "metadata": {
        "id": "OYVNPXlQnnDh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv bdd100k_images_100k/labels /content/"
      ],
      "metadata": {
        "id": "2UXKAYjhnzce"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf bdd100k_images_100k"
      ],
      "metadata": {
        "id": "nRb5v0qLZZPV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5/"
      ],
      "metadata": {
        "id": "-AxiSkd2bHdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b4c993-6a9f-4d0b-f1cf-9a92dc9d7d32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/yolov5/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 Download configuration yaml"
      ],
      "metadata": {
        "id": "Qc68DTbvOsde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click `To Download the training parameters`. { display-mode: \"form\" }\n",
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/prasadmlexpert/objectidentificationvideo/main/yolov5reduced.yml -P /content/yolov7/data/"
      ],
      "metadata": {
        "id": "twWU7TNJbbiZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/yolov7/data/yolov5reduced.yml"
      ],
      "metadata": {
        "id": "U882UEQAb6wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbda74ff-6290-4a86-936e-a51e1cfb9d7a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../images/train\r\n",
            "val: ../images/val\r\n",
            "test: ../images/test\r\n",
            "\r\n",
            "nc: 11\r\n",
            "names: ['bicycle', 'bus', 'car', 'motorcycle', 'person', 'rider', 'traffic light', 'traffic sign', 'trailer', 'train', 'truck']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/yolov7/data/yolov5reduced.yml /content/yolov7/data/yolov7reduced.yaml"
      ],
      "metadata": {
        "id": "_FpaljAIPenY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean up unwanted folders"
      ],
      "metadata": {
        "id": "srMLkiICPBNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/yolov7/runs/train/exp*"
      ],
      "metadata": {
        "id": "L5wYMQ8FDr-7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt -P /content/yolov7/"
      ],
      "metadata": {
        "id": "UeUsFW1ZPDZ8",
        "outputId": "56aac2e6-7861-4923-e099-d25b082fb074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-18 01:35:28--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220918%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220918T013528Z&X-Amz-Expires=300&X-Amz-Signature=1e3058bf02b42bb87cbadae860db237db6ae8f361e8c81fb15718d49eda01947&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-09-18 01:35:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220918%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220918T013528Z&X-Amz-Expires=300&X-Amz-Signature=1e3058bf02b42bb87cbadae860db237db6ae8f361e8c81fb15718d49eda01947&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘/content/yolov7/yolov7_training.pt’\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M  29.7MB/s    in 2.4s    \n",
            "\n",
            "2022-09-18 01:35:31 (29.7 MB/s) - ‘/content/yolov7/yolov7_training.pt’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 install wan db to save training information"
      ],
      "metadata": {
        "id": "ulAGJgFnTC08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click `To install wandb to log traces`. { display-mode: \"form\" }\n",
        "%%capture\n",
        "!pip install wandb"
      ],
      "metadata": {
        "id": "QdAf0cPGxn0p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5 Train \n",
        "Options:\n",
        "img - input image size to model(compressed image size)\n",
        "\n",
        "1. batch - batch size (training per batch)\n",
        "2. epoch - number of training\n",
        "3. data - configuration yml\n",
        "4. weights - weights to be used\n",
        "5. freeze(optional) - number of layers -1 to freeze in 24 layers"
      ],
      "metadata": {
        "id": "ESPD_z_3P0nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5.A Train with pre trained data set"
      ],
      "metadata": {
        "id": "EOTX8XvuRJ_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure to configure wandb account"
      ],
      "metadata": {
        "id": "xMugaPsvTQju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov7"
      ],
      "metadata": {
        "id": "-jg4Zj9tPQ8G",
        "outputId": "859b0699-f3d5-4e32-e900-15879ec9f55b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 16 --data data/yolov7reduced.yaml --img 640 640 --cfg cfg/training/yolov7-custom.yaml --weights 'yolov7_training.pt' --name yolov7-custom --hyp data/hyp.scratch.custom.yaml --freeze 24 --epochs 1\n"
      ],
      "metadata": {
        "id": "E8vc0InWPYfK",
        "outputId": "e850d81e-5661-4d46-aa98-3b8a3c35fafd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 v0.1-112-g55b90e1 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7-custom.yaml', data='data/yolov7reduced.yaml', device='0', entity=None, epochs=1, evolve=False, exist_ok=False, freeze=[24], global_rank=-1, hyp='data/hyp.scratch.custom.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='yolov7-custom', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov7-custom2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprasadmlexpert\u001b[0m (\u001b[33mgroup7iiith18\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20220918_015539-1why8ipd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov7-custom2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/group7iiith18/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/group7iiith18/YOLOR/runs/1why8ipd\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     88096  models.yolo.IDetect                     [11, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37250496 parameters, 37250496 gradients, 105.3 GFLOPS\n",
            "\n",
            "Transferred 555/566 items from yolov7_training.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "freezing model.2.conv.weight\n",
            "freezing model.2.bn.weight\n",
            "freezing model.2.bn.bias\n",
            "freezing model.3.conv.weight\n",
            "freezing model.3.bn.weight\n",
            "freezing model.3.bn.bias\n",
            "freezing model.4.conv.weight\n",
            "freezing model.4.bn.weight\n",
            "freezing model.4.bn.bias\n",
            "freezing model.5.conv.weight\n",
            "freezing model.5.bn.weight\n",
            "freezing model.5.bn.bias\n",
            "freezing model.6.conv.weight\n",
            "freezing model.6.bn.weight\n",
            "freezing model.6.bn.bias\n",
            "freezing model.7.conv.weight\n",
            "freezing model.7.bn.weight\n",
            "freezing model.7.bn.bias\n",
            "freezing model.8.conv.weight\n",
            "freezing model.8.bn.weight\n",
            "freezing model.8.bn.bias\n",
            "freezing model.9.conv.weight\n",
            "freezing model.9.bn.weight\n",
            "freezing model.9.bn.bias\n",
            "freezing model.11.conv.weight\n",
            "freezing model.11.bn.weight\n",
            "freezing model.11.bn.bias\n",
            "freezing model.13.conv.weight\n",
            "freezing model.13.bn.weight\n",
            "freezing model.13.bn.bias\n",
            "freezing model.14.conv.weight\n",
            "freezing model.14.bn.weight\n",
            "freezing model.14.bn.bias\n",
            "freezing model.15.conv.weight\n",
            "freezing model.15.bn.weight\n",
            "freezing model.15.bn.bias\n",
            "freezing model.17.conv.weight\n",
            "freezing model.17.bn.weight\n",
            "freezing model.17.bn.bias\n",
            "freezing model.18.conv.weight\n",
            "freezing model.18.bn.weight\n",
            "freezing model.18.bn.bias\n",
            "freezing model.19.conv.weight\n",
            "freezing model.19.bn.weight\n",
            "freezing model.19.bn.bias\n",
            "freezing model.20.conv.weight\n",
            "freezing model.20.bn.weight\n",
            "freezing model.20.bn.bias\n",
            "freezing model.21.conv.weight\n",
            "freezing model.21.bn.weight\n",
            "freezing model.21.bn.bias\n",
            "freezing model.22.conv.weight\n",
            "freezing model.22.bn.weight\n",
            "freezing model.22.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../labels/train.cache' images and labels... 69863 found, 137 missing, 10 empty, 0 corrupted: 100% 70000/70000 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../labels/val.cache' images and labels... 10000 found, 0 missing, 0 empty, 0 corrupted: 100% 10000/10000 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.13, Best Possible Recall (BPR) = 0.9613. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 24355 of 1274792 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1274508 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9988 best possible recall, 4.32 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.296/0.714-mean/best, past_thr=0.485-mean: 7,7,  13,13,  16,31,  28,18,  48,34,  39,80,  85,55,  136,104,  209,184\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7473: 100% 1000/1000 [05:06<00:00,  3.26it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9996 best possible recall, 5.30 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.346/0.747-mean/best, past_thr=0.494-mean: 5,7,  10,8,  8,15,  15,13,  25,19,  14,36,  44,33,  75,57,  152,118\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/yolov7-custom2\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/0     5.91G   0.05172   0.06132   0.02849    0.1415       446       640: 100% 4375/4375 [1:11:06<00:00,  1.03it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 313/313 [03:27<00:00,  1.51it/s]\n",
            "                 all       10000      186033       0.782       0.309       0.361       0.191\n",
            "             bicycle       10000        1039       0.649       0.285       0.336       0.158\n",
            "                 bus       10000        1660       0.622        0.45       0.479       0.348\n",
            "                 car       10000      102837       0.747       0.671       0.736       0.423\n",
            "          motorcycle       10000         460           1           0      0.0834      0.0371\n",
            "              person       10000       13426       0.693       0.543       0.593       0.274\n",
            "               rider       10000         658           1           0       0.196      0.0895\n",
            "       traffic light       10000       26884       0.629       0.447       0.478       0.158\n",
            "        traffic sign       10000       34724       0.667       0.504       0.555        0.27\n",
            "             trailer       10000           2           1           0           0           0\n",
            "               train       10000          15           1           0    1.94e-05    1.46e-05\n",
            "               truck       10000        4328       0.597       0.498       0.513       0.348\n",
            "1 epochs completed in 1.247 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/yolov7-custom2/weights/last.pt, 74.9MB\n",
            "Optimizer stripped from runs/train/yolov7-custom2/weights/best.pt, 74.9MB\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.3608\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.1913\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.78213\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.30893\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.05172\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02849\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.06132\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.0934\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.02268\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.06934\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00333\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00333\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.07001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33myolov7-custom2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/group7iiith18/YOLOR/runs/1why8ipd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 54 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220918_015539-1why8ipd/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/yolov7/runs/train/yolov7-custom2/weights"
      ],
      "metadata": {
        "id": "jERlqyjD9ZD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a483c77-0e3a-4c39-9ef8-ae77d8741228"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 579240\n",
            "-rw-r--r-- 1 root root  74891785 Sep 18 03:16 best.pt\n",
            "-rw-r--r-- 1 root root 293891712 Sep 18 03:16 epoch_000.pt\n",
            "-rw-r--r-- 1 root root 149456783 Sep 18 02:01 init.pt\n",
            "-rw-r--r-- 1 root root  74891785 Sep 18 03:16 last.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5.B copy trained weights(best and last)"
      ],
      "metadata": {
        "id": "84N59D03Q0x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/yolov7/runs/train/yolov7-custom/weights/* ./"
      ],
      "metadata": {
        "id": "UWg63gpG9ecG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 5.C cleanup"
      ],
      "metadata": {
        "id": "Rv70X5DGQ-ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/yolov7/runs/train/yolov7-custom*"
      ],
      "metadata": {
        "id": "HxGu9p8895xT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5.D continue training with re trained model"
      ],
      "metadata": {
        "id": "y8-r_F7DRUjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --workers 8 --device 0 --batch-size 16 --data data/yolov7reduced.yaml --img 640 640 --cfg cfg/training/yolov7-custom.yaml --weights 'last.pt' --name yolov7-custom --hyp data/hyp.scratch.custom.yaml --epochs 2"
      ],
      "metadata": {
        "id": "ygQgoC9d9_bW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424496a8-6925-4ce4-e076-733459581205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOR 🚀 v0.1-112-g55b90e1 torch 1.12.1+cu113 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7-custom.yaml', data='data/yolov7reduced.yaml', device='0', entity=None, epochs=2, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.custom.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='yolov7-custom', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov7-custom', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, v5_metric=False, weights='last.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprasadmlexpert\u001b[0m (\u001b[33mgroup7iiith18\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20220918_032326-1695y1jb\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myolov7-custom\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/group7iiith18/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/group7iiith18/YOLOR/runs/1695y1jb\u001b[0m\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     88096  models.yolo.IDetect                     [11, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37250496 parameters, 37250496 gradients, 105.3 GFLOPS\n",
            "\n",
            "Transferred 564/566 items from last.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../labels/train.cache' images and labels... 69863 found, 137 missing, 10 empty, 0 corrupted: 100% 70000/70000 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../labels/val.cache' images and labels... 10000 found, 0 missing, 0 empty, 0 corrupted: 100% 10000/10000 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.13, Best Possible Recall (BPR) = 0.9613. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 24355 of 1274792 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 1274508 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9988 best possible recall, 4.32 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=640, metric_all=0.296/0.714-mean/best, past_thr=0.485-mean: 7,7,  13,13,  16,31,  28,18,  48,34,  39,80,  85,55,  136,104,  209,184\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7371:  32% 315/1000 [01:39<03:34,  3.20it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/yolov7/runs/train/yolov7-custom/weights/* ./"
      ],
      "metadata": {
        "id": "Sj5-QMTCntGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If satisfied with model performace please continue. If not satisfied re train model from [Step 5.B] to [Step 5.D]"
      ],
      "metadata": {
        "id": "8eZWCLhFRmYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6 Download model to local PC"
      ],
      "metadata": {
        "id": "EdMqJJIiRf3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/yolov7/best.pt') \n",
        "files.download('/content/yolov7/last.pt') "
      ],
      "metadata": {
        "id": "nNrpJKHN-L2i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ca61dacb-a2c7-4d79-8d85-47bf15499b7e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ad11a48-73c3-49da-b967-42405c09b81f\", \"best.pt\", 74891785)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_45f0770e-df11-4738-b983-e29a41e791e1\", \"last.pt\", 74891785)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7 Save model to google drive"
      ],
      "metadata": {
        "id": "YYIDCAkBSGJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gar1jxgRLLd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/weights"
      ],
      "metadata": {
        "id": "fiNZMJ2zLmNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/yolov7/best.pt /content/drive/MyDrive/weights/yolov7_best.pt"
      ],
      "metadata": {
        "id": "8QYANP0uLRMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/yolov7/last.pt /content/drive/MyDrive/weights/yolov7_last.pt"
      ],
      "metadata": {
        "id": "NlyIkOb9MeKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}